\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}

\usepackage{url}

\usepackage{geometry}
\newgeometry{left=12mm, right=17mm, top= 12mm, bottom=12mm}


\usepackage{graphicx}
\usepackage{float}
\usepackage[usenames,dvipsnames]{xcolor}

% Reset line counter for each align environment
\usepackage{etoolbox}
\AtBeginEnvironment{align}{\setcounter{equation}{0}}

\usepackage{amsmath, amsfonts, mathtools, amsthm, amssymb}
\usepackage{mathrsfs}
\usepackage{cancel}
\usepackage{enumitem} % alphanumeric enumerate
% horizontal rule
\newcommand\hr{
    \noindent\rule[0.5ex]{\linewidth}{0.5pt}
}

\usepackage{tikz}
\usepackage{tikz-cd}

% theorems
\usepackage{thmtools}
\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{skipabove=1em,skipbelow=0em, innertopmargin=5pt, innerbottommargin=6pt}

\theoremstyle{definition}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, mdframed={ nobreak } ]{thmgreenbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, mdframed={ nobreak } ]{thmredbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont]{thmbluebox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont]{thmblueline}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, numbered=no, mdframed={ rightline=false, topline=false, bottomline=false, }, qed=\qedsymbol ]{thmproofbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, numbered=no, mdframed={ nobreak, rightline=false, topline=false, bottomline=false } ]{thmexplanationbox}
\declaretheorem[style=thmgreenbox, name=Definition]{definition}
\declaretheorem[sibling=definition, style=thmredbox, name=Corollary]{corollary}
\declaretheorem[sibling=definition, style=thmredbox, name=Proposition]{prop}
\declaretheorem[sibling=definition, style=thmredbox, name=Theorem]{theorem}
\declaretheorem[sibling=definition, style=thmredbox, name=Lemma]{lemma}
\declaretheorem[numbered=no, style=thmexplanationbox, name=Proof]{explanation}
\declaretheorem[numbered=no, style=thmproofbox, name=Proof]{replacementproof}
\declaretheorem[style=thmbluebox,  numbered=no, name=Exercise]{ex}
\declaretheorem[style=thmbluebox,  numbered=no, name=Example]{eg}
\declaretheorem[style=thmblueline, numbered=no, name=Remark]{remark}
\declaretheorem[style=thmblueline, numbered=no, name=Note]{note}


\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{graphicx}
\usepackage{dirtytalk}

% include figure stored at ./figures/name.pdf_tex
\newcommand{\incfig}[1]{
  \def\svgwidth{0.5\columnwidth}
  \import{./figures/}{#1.pdf_tex}
}

\title{Math 340: Lec 14 Big Ideas Journal (Discrete joint, marginal, and conditional distributions)}
\author{Asa Royal (ajr74)}
\date{February 27, 2024}

\begin{document}
\maketitle

\subsection*{Definition of distributions}
\begin{definition}[joint distribution]
  Let \( X \) and \( Y \) be two discrete random variables. The joint distribution is \( \mathbb{P}(X=k, Y=j) \) for \( k \in R(X), j \in R(Y) \). 
\end{definition}

\begin{remark}
  The joint distribution can be considered a mass function with domain in the 2D-plane. 
\end{remark}

\begin{remark}
  If \( X, Y \) are independent, \( \mathbb{P}(X=k, Y=j) = \mathbb{P}(X=k) \mathbb{P}(Y=j) \), and we say that the joint probability distribution has a product structure. 
\end{remark}
\begin{definition}[marginal distribution]
  Let \( X \) be a discrete random variable. The marginal distribution of \( X \) is \( \mathbb{P}(X=k) \). 
\end{definition}

\begin{remark}
  Even if a set of three random variables have the same marginal distributions, they may have different joint distributions if one of the random variables is dependent on another. 
\end{remark}


\begin{definition}[Conditional distribution]
  Let \( X \) and \( Y \) be discrete random variables. A conditional distribution looks like \( \mathbb{P}(X=k|Y-j) \). Note that
  \begin{equation*}
    \mathbb{P}(X=k|Y=j) = \frac{\mathbb{P}(X=k, Y=j}{\mathbb{P}(Y=j)}
  \end{equation*}
\end{definition}


\subsection*{Moving between distributions}

\begin{remark}
  We can find the marginal distribution \( \mathbb{P}(X=k|Y=j) \) given the joint probability distribution \( \mathbb{P}(X=k,Y=j) \) by normalizing the joint probabilities of \( X \) and \( Y \) for a given \( Y=j \). We can use the same process to find \( \mathbb{P}(Y=j|X=k) \). 
\end{remark}

\begin{remark}
  We can relate the joint and marginal distributions using the partition rule. In particular, if we know the joint distributions of \( X \) and some some other r.v. \( Y \), we can recover the marginal distribution of \( X \) ( and/or \( Y \)). But if we know the marginal distribution of \( X \), we cannot recover the joint distribution of \( X \) and \( Y \) without add'l info. \\
  \\
\end{remark}

\begin{eg}[Calculating expected value of the marginal distribution using the conditional]
  By the partition rule, 
  \begin{equation*}
    \mathbb{E}[X] = \sum_{j \in R(Y)} \mathbb{E}[X|Y=j) \mathbb{P}(Y=j)
  \end{equation*}
  This lets us calculate \( \mathbb{E}[X] \) when it's difficult to think directly about \( X \) but easier to think about \( X|Y \). And note
  \begin{equation*}
    \mathbb{E}[X|Y=j] = \sum_{k \in R(X)} k \mathbb{P}(X=k|Y=j)
  \end{equation*}
\end{eg}

\end{document}
