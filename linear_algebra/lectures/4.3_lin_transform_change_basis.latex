\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}

\usepackage{url}

\usepackage{geometry}
\newgeometry{left=12mm, right=17mm, top= 12mm, bottom=12mm}


\usepackage{graphicx}
\usepackage{float}
\usepackage[usenames,dvipsnames]{xcolor}

% Reset line counter for each align environment
\usepackage{etoolbox}
\AtBeginEnvironment{align}{\setcounter{equation}{0}}

\usepackage{amsmath, amsfonts, mathtools, amsthm, amssymb}
\usepackage{mathrsfs}
\usepackage{cancel}
\usepackage{enumitem} % alphanumeric enumerate

\newcommand\N{\ensuremath{\mathbb{N}}}
\newcommand\R{\ensuremath{\mathbb{R}}}
\newcommand\Z{\ensuremath{\mathbb{Z}}}
\renewcommand\O{\ensuremath{\emptyset}}
\newcommand\Q{\ensuremath{\mathbb{Q}}}
\newcommand\C{\ensuremath{\mathbb{C}}}
\let\implies\Rightarrow
\let\impliedby\Leftarrow
\let\iff\Leftrightarrow
\let\epsilon\varepsilon
\DeclareMathOperator{\Img}{Im}

% horizontal rule
\newcommand\hr{
    \noindent\rule[0.5ex]{\linewidth}{0.5pt}
}

\usepackage{tikz}
\usepackage{tikz-cd}

% theorems
\usepackage{thmtools}
\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{skipabove=1em,skipbelow=0em, innertopmargin=5pt, innerbottommargin=6pt}

\theoremstyle{definition}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, mdframed={ nobreak } ]{thmgreenbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, mdframed={ nobreak } ]{thmredbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont]{thmbluebox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont]{thmblueline}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, numbered=no, mdframed={ rightline=false, topline=false, bottomline=false, }, qed=\qedsymbol ]{thmproofbox}
\declaretheoremstyle[headfont=\bfseries\sffamily, bodyfont=\normalfont, numbered=no, mdframed={ nobreak, rightline=false, topline=false, bottomline=false } ]{thmexplanationbox}
\declaretheorem[style=thmgreenbox, name=Definition]{definition}
\declaretheorem[sibling=definition, style=thmredbox, name=Corollary]{corollary}
\declaretheorem[sibling=definition, style=thmredbox, name=Proposition]{prop}
\declaretheorem[sibling=definition, style=thmredbox, name=Theorem]{theorem}
\declaretheorem[sibling=definition, style=thmredbox, name=Lemma]{lemma}
\declaretheorem[numbered=no, style=thmexplanationbox, name=Proof]{explanation}
\declaretheorem[numbered=no, style=thmproofbox, name=Proof]{replacementproof}
\declaretheorem[style=thmbluebox,  numbered=no, name=Exercise]{ex}
\declaretheorem[style=thmbluebox,  numbered=no, name=Example]{eg}
\declaretheorem[style=thmblueline, numbered=no, name=Remark]{remark}
\declaretheorem[style=thmblueline, numbered=no, name=Note]{note}


\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{graphicx}

% include figure stored at ./figures/name.pdf_tex
\newcommand{\incfig}[1]{
  \def\svgwidth{0.5\columnwidth}
  \import{./figures/}{#1.pdf_tex}
}


% Matrix with row vectors (see https://tex.stackexchange.com/a/454734)
\newcommand{\brows}[1]{%
  \begin{bmatrix}
  \begin{array}{@{\protect\rotvert\;}c@{\;\protect\rotvert}}
  #1
  \end{array}
  \end{bmatrix}
}
% rotated vertical line (used for matrix w/ row vectors)
\newcommand{\rotvert}{\rotatebox[origin=c]{90}{$\vert$}}
% vertical dot rows in a matrix
\newcommand{\rowsvdots}{\multicolumn{1}{@{}c@{}}{\vdots}}

\title{%
  Math 221 Lec 16  \\
  \large{4.3: Linear transformations \& change of basis}
}
\author{Asa Royal (ajr74)}
\date{11/2/23, 11/9/23}

\begin{document}
\maketitle

\begin{definition}[linear transformation]
  A function \( T: \mathbb{R}^n \mapsto \mathbb{R}^m \) is called a \textbf{linear transformation} if it satisfies
  \begin{enumerate}
    \item \( T(\textbf{x} + \textbf{y}) = T(\textbf{x}) + T(\textbf{y}) \forall \textbf{x}, \textbf{y} \in \mathbb{R}^n \)
    \item \( T(c \textbf{x}) = c T(\textbf{x}) \forall \textbf{x} \in \mathbb{R}^n \) and scalars \( c \)
  \end{enumerate}
\end{definition}

\begin{remark}
  If \( T: \mathbb{R}^n \mapsto \mathbb{R}^m \) is a linear transformation, then we can find a matrix \( A \), the so-called standard matrix of \( A \) so that \( T= \mu_A \). THe \( j \)th column of \( A \) is given by \( T(\textbf{e})j \), where \( \textbf{e}_j \) is the \( j \)th standard basis vector. 
\end{remark}

\begin{prop}
  Let \( T: \mathbb{R}^n \mapsto \mathbb{R}^m \) be a linear transformation and let \( \mathcal{E} = \{ \textbf{e}_1, \ldots , \textbf{e}_n \} \) be the stanadard basis for \( \mathbb{R}^n \). LEt \( A \) be the matrix whose column vectors are the vectors \( T(\textbf{e}_1), \ldots , T(\textbf{e})_n \in \mathbb{R}^m \) (that is, the coordintae vectors of \( T(\textbf{e}_j) \) with respect to the standard basis of \( \mathbb{R}^m \): 
  \[
    A = \begin{bmatrix}
      \lvert & \lvert & & \lvert \\
      T(\textbf{e})_1 & T(\textbf{e})_2 & \ldots  & T(\textbf{e})_n \\
      \lvert & \lvert & & \lvert
    \end{bmatrix}
  \]
Then \( T= \mu_A \) and we call \( A \) the standard matrix for \( T \), denoted \( [T]_{\text{stand}} \). 
\end{prop}

\begin{proof}
\end{proof}

\begin{definition}[matrix with respect to basis]
  Let \( T: \mathbb{R}^n \mapsto \mathbb{R}^n \) be a linear transformation and let \( \mathcal{B} = \{ \textbf{v}_1, \ldots , \textbf{v}_n \} \) be an ordered basis for \( \mathbb{R}^n \). For each \( j=1,\ldots , n \), let \( a_{1j}, a_{2j}, \ldots  a_{nj} \) denote the coordinates of \( T(\textbf{v}_j) \) with respect to the basis \( \mathcal{B} \). We denote this matrix by \( [T]_{\mathcal{B}} \). 
\end{definition}

\begin{remark}
  The coefficients of \( T(\textbf{v}_j) \) will be entered as the \( j \)th column of the matrix \( [T]_{\mathcal{B}} \). I.e. given a vector \( \textbf{x} \in \mathbb{R}^n \), we let \( C_{\mathcal{B}(\textbf{x})} \) denote the colum vector whose entires are the coordinates of \( \textbf{x} \) w.r.t. the basis of \( \mathcal{B} \). That is, if \( \{ \textbf{v}_1,\ldots ,\textbf{v}_n \} \) is a basis for \( \mathcal{B} \), 
  \[
    \textbf{x} = c_1 \textbf{v}_1 + c_2 \textbf{v}_2 + \ldots  c_n \textbf{v}_n
  \]
then 
  \[
    C_{\mathcal{B}(\textbf{x})} = \begin{bmatrix}
      c_1 \\ c_2 \\ \vdots \\ c_n 
    \end{bmatrix}
      \]
  So 

  \[
    [T]_{\mathcal{B}} = \begin{bmatrix}
      \lvert & \lvert & & \lvert \\
    C_{\mathcal{B}}(T(\textbf{v}_1)) & C_{\mathcal{B}} (T(\textbf{v}_2)) & \ldots & C_{\mathcal{B}} (T(\textbf{v}_n)) \\
          \lvert & \lvert & & \lvert
    \end{bmatrix}
  \]
\end{remark}

\begin{definition}[coordinates w.r.t. basis]
  Let \( V \) be a subspace of \( \mathbb{R}^n \) and let \( \mathcal{B} = \{\textbf{v}_1, \textbf{v}_2, \ldots , \textbf{v}_k \} \) be a basis for \(  V \). Then for \( \textbf{v} \in V, \textbf{v}= c_1 \textbf{v}_1 + \ldots  + c_k \textbf{v}_k \). \( c_1, \ldots , c_k \) are the coordinates of \( \textbf{v} \) with respect to basis \( \mathcal{B} \). 
\end{definition}

\begin{eg}
  Say \( \mathcal{B} = \{\textbf{v}_1, \textbf{v}_2 \} \) is a basis for \( \mathbb{R}^2 \) with \( \textbf{v}_1 = \begin{bmatrix} 2 \\ 1 \end{bmatrix} \) and \( \textbf{v}_2 = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \). Further, let's consider the vector \( \textbf{a} = \begin{bmatrix} 8 \\ 7 \end{bmatrix} \). Note that \( \textbf{a} = 3 \textbf{v}_1 + 2 \textbf{v}_2 \). So \( {\begin{bmatrix} \textbf{a} \end{bmatrix}}_{\mathcal{B}} = \begin{bmatrix} 3 \\ 2 \end{bmatrix} \). That is, the coordinates for \( \textbf{a} \) with respect to the basis \( \mathcal{B} \) are \( \begin{bmatrix} 3 \\ 2 \end{bmatrix} \)
\end{eg}

\begin{remark}
  When we talk offhand about Cartesian coordinates \( (2,1) \) for example, we are usually referring to those as coordinates with respect to the standard basis for \( \mathbb{R}^2 \), \( \begin{bmatrix} \textbf{e}_1 & \textbf{e}_2 \end{bmatrix} \). \( (2,1) = 2\textbf{e}_1 + 1 \textbf{e}_2 \). 
\end{remark}

\begin{definition}[change-of-basis matrix]
  The change of basis matrix for some basis \( \mathcal{B} = \{ \textbf{v}_1, \ldots , \textbf{v}_k  \} \) is simply \( \begin{bmatrix} \textbf{v}_1 & \ldots  &  \textbf{v}_2 \end{bmatrix} \). It represents the linear transformation of basis vectors in one basis to basis vectors in another. 
\end{definition}

\begin{eg}
  Imagine we have \( \begin{bmatrix} -1 \\ 2 \end{bmatrix} \) in some basis \( \mathcal{B} = \left\{ \begin{bmatrix} 1 \\ 2 \end{bmatrix}, \begin{bmatrix} 2 \\ 3 \end{bmatrix} \right\} \) and we want to get its coordinates in the standard basis. Then \( \begin{bmatrix} 1 & 2 \\ 2 & 3  \end{bmatrix} \) is the change of basis matrix between \( \mathcal{B} \)   and \( \mathcal{\varepsilon} \), so we can take \( \begin{bmatrix} 1 & 2 \\ 2 & 3 \end{bmatrix}  \begin{bmatrix} -1 \\ 2 \end{bmatrix}\) and get coordinates w.r.t. the standard basis. 
  \\
  \\
  If we had \( \begin{bmatrix} -1 \\ 2 \end{bmatrix} \) in standard basis coordinates and wanted to find its coordinates with respect to \( \mathcal{B} \), We could take \( \begin{bmatrix} 1 & 2 \\ 2 & 3 \end{bmatrix}^{-1} \begin{bmatrix} -1 \\ 2 \end{bmatrix} \). 
\end{eg}

\begin{remark}
  Can kinda think of the change of basis matrix as translating between coordinate systems (languages for representing vectors). The matrix with basis 2's basis vectors written in coordinates (language) of basis 1 shows how to translate basis 2's coordinates into basis 1 coordinates (language). 
\end{remark}

\begin{remark}
  We can figure out coordinates for linear transformations in any basis through the following process. Imagine a matrix \( A \) that represents linear transformation \( T \) in some basis \( \mathcal{B_1} \), and we want to find the matrix \( [T]_{\mathcal{B}_2} \), which tells us how \( T \) affects vectors with coordinates written w.r.t. basis \( \mathcal{B}_2 \). First, we take some vector \( \textbf{x} \) with coordinates in \( \mathcal{B}_1 \) and convert its coordinates to \( \mathcal{B}_1 \). How? Change of basis matrix \( P \) = basis vectors of \( \mathcal{B}_2 \). So we take \( P \textbf{x} \). We then apply the linear transformation \( T \), as represented by \( A \) in \( \mathcal{B_1} \), which gives us \( AP \textbf{x} \). Finally, we convert coordinates back to \( \mathcal{B}_2 \). Then the coordinates for \( T[\textbf{x}] \) w.r.t. \( \mathcal{B}_2 \) are given by  \( P^{-1} A P  \). 
\end{remark}

\begin{remark}
  If \( T: \mathbb{R}^n \mapsto \mathbb{R}^n \) maps \( \textbf{x} \mapsto T(\textbf{x}) \), \( T \) of course maps \( [\textbf{x}]_{\mathcal{B}} \mapsto T(\textbf{x})_{\mathcal{B}} \), since the vectors in the latter statement are the same ones as in the first, simply expresssed w.r.t a different basis. But the matrix we use to represent \( T \) changes depending on the basis we're operating w.r.t. see below
\end{remark}

\begin{remark}
  Why would we transform bases? Some matrices are much easier to multiply in certain bases. For example, if we can transform a matrix into a basis where it's diagonal, we save a lot of multiplication computations. 
\end{remark}

\begin{definition}[alt. def matrix w.r.t. basis]
  The linear transformation of basis vectors \( \textbf{v}_1,\ldots ,\textbf{v}_n \) is a linear combination of of basis vectors \( \textbf{w}_1, \ldots , \textbf{w}_m \) (from the target basis) with coefficients (coordinates) given by the matrix \( [T]_{\mathcal{V}, \mathcal{W}} \). The \( j \)th column of \( [T]_{\mathcal{V}, \mathcal{W}} \) provides the coordinates for \( T[\textbf{v}_j] \) w.r.t. \( \textbf{w}_1, \ldots , \textbf{w}_m \)
  \begin{equation}
    T \begin{bmatrix}
      \textbf{v}_1 & \ldots  & ... & \textbf{v}_n 
    \end{bmatrix} 
    = 
    \begin{bmatrix}
      \textbf{w}_1 & \ldots  & \textbf{w}_m
    \end{bmatrix}
    [T]_{\mathcal{V}, \mathcal{W}}
  \end{equation}
\end{definition}

\begin{remark}
  Per the definition above, \( T(\textbf{v}_1) \in W \), which means \( T\textbf{v}_1  \) is a linear combination of the combination of \( \textbf{w}_i \). Which linear combination? The combination given by \( T\textbf{v}_1 = a_{11} \textbf{w}_1 + \ldots  + a_{m_1} \textbf{w}_m = \begin{bmatrix} \textbf{w}_1 & \ldots  & \textbf{w}_m \end{bmatrix} \begin{bmatrix} a_{11} \\ \vdots \\ a_{m1} \end{bmatrix}\)
\end{remark}

\begin{remark}
  If we set \( A = [T]_{\mathcal{V}, \mathcal{W}} \in \mathbb{R}^{m \times n} \), saying \( A \textbf{x} = \textbf{b} \) means that the coefficients of \( \textbf{x} \) of \( \textbf{v} \in V \) on \( \textbf{v}_1, \ldots , \textbf{v}_n \) get taken to the coefficients \( \textbf{b} \) of \( \textbf{w} \in W \) on \( \textbf{w}_1, \ldots , \textbf{w}_m \) by \( A=[T]_{\mathcal{V}, \mathcal{W}} \). 
\end{remark}

\begin{lemma}
  Fix \( V \) with basis \( \textbf{v}_1, \ldots , \textbf{v}_n \). If \( \textbf{v}_1', \ldots , \textbf{v}_n' \) is another basis of \( V \) then
  \begin{equation*}
    \begin{bmatrix} \textbf{v}_1' & \ldots  & \textbf{v}_n' \end{bmatrix} = \begin{bmatrix} \textbf{v}_1 & \ldots  & \textbf{v}_n \end{bmatrix} P 
  \end{equation*}
  for some invertible \( P \in \mathbb{R}^{n \times n} \). 
\end{lemma}

\begin{remark}
  Why? Because each \( \textbf{v}_i' \) can be expressed as a linear combination of the vectors \( \textbf{v}_1, \ldots , \textbf{v}_n \). Embed coefficients for the \( \textbf{v}_1, \ldots , \textbf{v}_n \) into the \( i \)th column of \( P \). Note: We expect \( P \) to be invertible, because each \( \textbf{v}_i \) can also be expressed as a linear combination of \( \textbf{v}_1', \ldots , \textbf{v}_n' \). 
\end{remark}

\begin{proof}
  The remark above serves as proof that \( P \) exists, but we can state more simply  that \( P = [\text{id}_V]_{\mathcal{V}', \mathcal{V}} \). I.e., P is the matrix for the identity linear transformation (that does absolutely nothing) with an input expressed w.r.t. \( \mathcal{V}' \) and output expressed w.r.t. \( \mathcal{V} \). We can show \( P \) is invertible by showing that \( \textbf{x} \in N(P) \implies \textbf{x} = \textbf{0} \). If \( \textbf{x} \in N(P) \),
  \begin{equation*}
    \begin{bmatrix} \textbf{v}_1' & \ldots  & \textbf{v}_n' \end{bmatrix} = \begin{bmatrix} \textbf{v}_1 & \ldots  & \textbf{v}_n \end{bmatrix} P\textbf{x} = 0 
  \end{equation*}
  Which means \( x_1 \textbf{v}_1' + \ldots  + x_n \textbf{v}_n' = 0 \). But \( \textbf{v}_1', \ldots , \textbf{v}_n' \) are linearly independent, so \( \textbf{x} = \textbf{0} \)
\end{proof}

\begin{definition}[change of basis matrix take 1000]
  \( P \) above is the change of basis matrix. It tells us how to express the basis vectors of \( V' \) in terms of the vectors of \( V \). Again, see proof above--the change of basis matrix is the matrix for the identity linear transformation with an different input and output basis. 
\end{definition}

\begin{definition}[change-of-basis formula]
  Fix 
  \begin{itemize}
    \item a linear map \( T: V \mapsto W \) 
    \item ordered bases \\
      \( \mathcal{V}, \mathcal{V}' \) for \( V \) with \(\begin{bmatrix} \textbf{v}_1' & \ldots  & \textbf{v}_n'  \end{bmatrix} = \begin{bmatrix} \textbf{v}_1 & \ldots  & \textbf{v}_n  \end{bmatrix}P\), \\
      \( \mathcal{W}, \mathcal{W}' \) for \( W \) with \(\begin{bmatrix} \textbf{w}_1' & \ldots  & \textbf{w}_n'  \end{bmatrix} = \begin{bmatrix} \textbf{w}_1 & \ldots  & \textbf{w}_n  \end{bmatrix}Q\)
    \item \( A = [T]_{\mathcal{V}, \mathcal{W}} \), \( A' = [T]_{\mathcal{V'}, \mathcal{W'}} \)
  \end{itemize}

  Then \( A' = Q^{-1} AP \)
\end{definition}

\begin{remark}
  \( A' \) is the matrix for the transform with respect to bases \( \mathcal{V}' and \mathcal{W}' \), so we know that a formula for it starts by taking in a vector \( \in V' \). It then changes bases from \( V' \) to \( V \) using \( P \), applies the linear transform \( T \), using coordinates from \( A \) so that the answer is w.r.t. basis \( W \), then uses \( Q^{-1} \) to convert from bases \( W  \) to \( W' \)\\
  For a basis \( \mathcal{B} \) and \( T:V \mapsto V \) (instead of \( T: V \mapsto W \)), we set \( [T]_{\mathcal{B}} = [T]_{\mathcal{B}, \mathcal{B}} \). \( [T]_{\mathcal{B}} \) takes the coefficients \( x \) of of \( \textbf{v} in V \) on \( \textbf{v}_1, \ldots , \textbf{v}_n \) to the coefficients of \( b \) of \( T \textbf{v} \) on \( \textbf{v}_1, \ldots , \textbf{v}_n \). 
\end{remark}
\end{document}

